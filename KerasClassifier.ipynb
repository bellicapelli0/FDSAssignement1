{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:32:03.198897Z",
     "start_time": "2020-09-21T13:31:58.667588Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stop_words import get_stop_words\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "filename = \"../training.1600000.processed.noemoticon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:32:21.334327Z",
     "start_time": "2020-09-21T13:32:16.584738Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, encoding='latin-1', names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "df = df[[\"text\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:32:43.202066Z",
     "start_time": "2020-09-21T13:32:21.336875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0   awww that s a bummer you shoulda got david ca...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2   i dived many times for the ball managed to sa...       0\n",
       "3    my whole body feels itchy and like its on fire        0\n",
       "4   no it s not behaving at all i m mad why am i ...       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean text\n",
    "text = df[\"text\"]\n",
    "text = text.str.replace(r'http?\\S+', ' ', regex=True)\n",
    "#text = text.str.replace(r'[#@]\\S+', ' ', regex=True)\n",
    "text = text.str.replace(r'@\\S+', ' ', regex=True)\n",
    "text = text.str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "text = text.str.replace(r'\\n', ' ', regex=True)\n",
    "text = text.str.replace(r' +', ' ', regex=True)\n",
    "text = text.str.lower()\n",
    "# Add cleaned text to df\n",
    "df = df.drop(columns = [\"text\"])\n",
    "df = pd.concat([text, df], axis=1, sort=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:32:43.236064Z",
     "start_time": "2020-09-21T13:32:43.204953Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "target = df[[\"target\"]].values.astype(float)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(target)\n",
    "normalized = pd.DataFrame(x_scaled)\n",
    "df[\"target\"] = normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:34:34.942946Z",
     "start_time": "2020-09-21T13:32:43.238581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>916312</th>\n",
       "      <td>tweeterizing from a mobile</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427558</th>\n",
       "      <td>date night its a surprise</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369132</th>\n",
       "      <td>i know right i got work at 7am</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065837</th>\n",
       "      <td>listening to dancing in the moonlight by toplo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942614</th>\n",
       "      <td>whoever forms the government it will be status...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  target\n",
       "916312                          tweeterizing from a mobile     1.0\n",
       "1427558                          date night its a surprise     1.0\n",
       "369132                      i know right i got work at 7am     0.0\n",
       "1065837  listening to dancing in the moonlight by toplo...     1.0\n",
       "942614   whoever forms the government it will be status...     1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmStopWords(tweet, stop_words):\n",
    "    text = tweet.split()\n",
    "    text = ' '.join(word for word in text if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "stop_words = get_stop_words('english')\n",
    "stop_words = [''.join(c for c in s if c not in string.punctuation) for s in stop_words]\n",
    "stop_words = [t.encode('utf-8') for t in stop_words]\n",
    "\n",
    "# Preprocess all tweet data\n",
    "pro_tweets = []\n",
    "for tweet in df['text']:\n",
    "    pro_stopw = rmStopWords(tweet, stop_words)\n",
    "    pro_tweets.append(pro_stopw)\n",
    "\n",
    "df['text'] = pro_tweets\n",
    "\n",
    "backup = df\n",
    "df = df.sample(n=1600000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:34:34.952321Z",
     "start_time": "2020-09-21T13:34:34.945175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "tags = df.target\n",
    "texts = df.text\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from tensorflow.keras import metrics\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:27:35.718796Z",
     "start_time": "2020-09-21T12:27:35.711158Z"
    }
   },
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:28:58.753605Z",
     "start_time": "2020-09-21T12:27:35.720671Z"
    }
   },
   "outputs": [],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:28:58.760303Z",
     "start_time": "2020-09-21T12:28:58.755703Z"
    }
   },
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:45:12.535311Z",
     "start_time": "2020-09-21T12:28:58.761749Z"
    }
   },
   "outputs": [],
   "source": [
    "# try a simple model first\n",
    "\n",
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])\n",
    "    print('compile done')\n",
    "    return model\n",
    "\n",
    "def check_model(model,x,y):\n",
    "    model.fit(x,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)\n",
    "\n",
    "simple_model = get_simple_model()\n",
    "check_model(simple_model,mat_texts,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:28:06.602846Z",
     "start_time": "2020-09-21T13:28:05.992407Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_model.save(\"simple_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:46:21.546827Z",
     "start_time": "2020-09-21T12:45:12.545319Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:19:35.642955Z",
     "start_time": "2020-09-21T12:46:21.554634Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v3():    # added filter\n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "cnn_model_v3 = get_cnn_model_v3()\n",
    "check_model(cnn_model_v3,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:28:25.600082Z",
     "start_time": "2020-09-21T13:28:24.802909Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model_v3.save(\"cnn_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:35:26.854785Z",
     "start_time": "2020-09-21T13:35:18.714596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orlando/anaconda3/envs/tfgpu/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user.name</th>\n",
       "      <th>user.screen_name</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>state</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all in collusion together nojustice trumppence</td>\n",
       "      <td>2016-08-12 10:04:02.194</td>\n",
       "      <td>Red Octopus</td>\n",
       "      <td>redoctapus</td>\n",
       "      <td>531</td>\n",
       "      <td>LA</td>\n",
       "      <td>['NOJUSTICE', 'TrumpPence']</td>\n",
       "      <td>['BarackObama', 'FBI', 'LorettaLynch', 'realDo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn newday clear trump deliberately throwing ...</td>\n",
       "      <td>2016-08-12 10:04:30.035</td>\n",
       "      <td>Beverly Spence</td>\n",
       "      <td>bspence5</td>\n",
       "      <td>2652</td>\n",
       "      <td>MD</td>\n",
       "      <td>['CNN', 'newday', 'Trump', 'ISIS']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kid you know suing someone thats the most bea...</td>\n",
       "      <td>2016-08-12 10:04:48.229</td>\n",
       "      <td>Rafael Alejandro</td>\n",
       "      <td>GinebraFilms</td>\n",
       "      <td>159</td>\n",
       "      <td>NJ</td>\n",
       "      <td>[]</td>\n",
       "      <td>['funnyordie', 'realDonaldTrump']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i totally concur this election is just cra cr...</td>\n",
       "      <td>2016-08-12 10:04:53.571</td>\n",
       "      <td>Kim Wasson</td>\n",
       "      <td>kimseacret3</td>\n",
       "      <td>244</td>\n",
       "      <td>MD</td>\n",
       "      <td>[]</td>\n",
       "      <td>['mike4193496', 'realDonaldTrump']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you are the co founder of isis you crooked ev...</td>\n",
       "      <td>2016-08-12 10:04:48.695</td>\n",
       "      <td>tom b</td>\n",
       "      <td>VNDISABLEDVET</td>\n",
       "      <td>68</td>\n",
       "      <td>TX</td>\n",
       "      <td>[]</td>\n",
       "      <td>['HillaryClinton']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                timestamp  \\\n",
       "0    all in collusion together nojustice trumppence   2016-08-12 10:04:02.194   \n",
       "1   cnn newday clear trump deliberately throwing ...  2016-08-12 10:04:30.035   \n",
       "2   kid you know suing someone thats the most bea...  2016-08-12 10:04:48.229   \n",
       "3   i totally concur this election is just cra cr...  2016-08-12 10:04:53.571   \n",
       "4   you are the co founder of isis you crooked ev...  2016-08-12 10:04:48.695   \n",
       "\n",
       "          user.name user.screen_name user.followers_count state  \\\n",
       "0       Red Octopus       redoctapus                  531    LA   \n",
       "1    Beverly Spence         bspence5                 2652    MD   \n",
       "2  Rafael Alejandro     GinebraFilms                  159    NJ   \n",
       "3        Kim Wasson      kimseacret3                  244    MD   \n",
       "4             tom b    VNDISABLEDVET                   68    TX   \n",
       "\n",
       "                             hashtags  \\\n",
       "0         ['NOJUSTICE', 'TrumpPence']   \n",
       "1  ['CNN', 'newday', 'Trump', 'ISIS']   \n",
       "2                                  []   \n",
       "3                                  []   \n",
       "4                                  []   \n",
       "\n",
       "                                            mentions  \n",
       "0  ['BarackObama', 'FBI', 'LorettaLynch', 'realDo...  \n",
       "1                                                 []  \n",
       "2                  ['funnyordie', 'realDonaldTrump']  \n",
       "3                 ['mike4193496', 'realDonaldTrump']  \n",
       "4                                 ['HillaryClinton']  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsdf = pd.read_csv(open('clean.csv','rU'), encoding='utf-8', engine='c').drop(columns=[\"Unnamed: 0\"])\n",
    "tweetsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:35:52.687497Z",
     "start_time": "2020-09-21T13:35:52.630666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(3000, 1000)\n"
     ]
    }
   ],
   "source": [
    "tweets = tweetsdf.sample(3000)[\"text\"].apply(str)\n",
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "\n",
    "mat_tweets = tok.texts_to_matrix(tweets,mode='count')\n",
    "\n",
    "print(mat_tweets[:5])\n",
    "print(mat_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:36:37.203810Z",
     "start_time": "2020-09-21T13:36:36.485755Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "simple_model = load_model('simple_model')\n",
    "simple_pred = simple_model.predict(mat_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:36:40.742946Z",
     "start_time": "2020-09-21T13:36:40.738352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5930077],\n",
       "       [0.5930077],\n",
       "       [0.5930077],\n",
       "       ...,\n",
       "       [0.5930077],\n",
       "       [0.5930077],\n",
       "       [0.5930077]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:47:08.805117Z",
     "start_time": "2020-09-21T13:47:08.767881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user.name</th>\n",
       "      <th>user.screen_name</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>state</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428622</th>\n",
       "      <td>seriously he will never admit he said it even if it s recorded trumpeteers will follow him over cliff regardless</td>\n",
       "      <td>2016-09-08 02:42:43.680</td>\n",
       "      <td>Joy Sayler</td>\n",
       "      <td>jsayler</td>\n",
       "      <td>1028</td>\n",
       "      <td>NV</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187220</th>\n",
       "      <td>stay woke</td>\n",
       "      <td>2016-08-24 00:38:41.203</td>\n",
       "      <td>Dilfof2016</td>\n",
       "      <td>TaylorBclark20</td>\n",
       "      <td>787</td>\n",
       "      <td>TX</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480631</th>\n",
       "      <td>or maybe it will be a powerpoint presentation or an excel data dump the possibilities are endless</td>\n",
       "      <td>2016-09-10 18:36:10.964</td>\n",
       "      <td>(((Kerri)))</td>\n",
       "      <td>klberney</td>\n",
       "      <td>357</td>\n",
       "      <td>NY</td>\n",
       "      <td>[]</td>\n",
       "      <td>['TerryOswald1', 'AP', 'HillaryClinton']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268796</th>\n",
       "      <td>have your followers turn off quality filter amp validate mute folder twitter using this to censor our followers from us</td>\n",
       "      <td>2016-08-29 00:43:01.078</td>\n",
       "      <td>❤️Boricua⛪️</td>\n",
       "      <td>NYRican4Trump</td>\n",
       "      <td>1531</td>\n",
       "      <td>GA</td>\n",
       "      <td>[]</td>\n",
       "      <td>['realDonaldTrump']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93378</th>\n",
       "      <td>just like the polls my advisors are rigged too donaldtrump on the campaign shakeup</td>\n",
       "      <td>2016-08-17 22:38:34.615</td>\n",
       "      <td>Jer-Jer</td>\n",
       "      <td>DALLASNITES</td>\n",
       "      <td>8287</td>\n",
       "      <td>IL</td>\n",
       "      <td>['DonaldTrump']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "428622  seriously he will never admit he said it even if it s recorded trumpeteers will follow him over cliff regardless            \n",
       "187220  stay woke                                                                                                                   \n",
       "480631   or maybe it will be a powerpoint presentation or an excel data dump the possibilities are endless                          \n",
       "268796   have your followers turn off quality filter amp validate mute folder twitter using this to censor our followers from us    \n",
       "93378    just like the polls my advisors are rigged too donaldtrump on the campaign shakeup                                         \n",
       "\n",
       "                      timestamp    user.name user.screen_name  \\\n",
       "428622  2016-09-08 02:42:43.680  Joy Sayler   jsayler           \n",
       "187220  2016-08-24 00:38:41.203  Dilfof2016   TaylorBclark20    \n",
       "480631  2016-09-10 18:36:10.964  (((Kerri)))  klberney          \n",
       "268796  2016-08-29 00:43:01.078  ❤️Boricua⛪️  NYRican4Trump     \n",
       "93378   2016-08-17 22:38:34.615  Jer-Jer      DALLASNITES       \n",
       "\n",
       "       user.followers_count state         hashtags  \\\n",
       "428622  1028                 NV    []                \n",
       "187220  787                  TX    []                \n",
       "480631  357                  NY    []                \n",
       "268796  1531                 GA    []                \n",
       "93378   8287                 IL    ['DonaldTrump']   \n",
       "\n",
       "                                        mentions  \n",
       "428622  []                                        \n",
       "187220  []                                        \n",
       "480631  ['TerryOswald1', 'AP', 'HillaryClinton']  \n",
       "268796  ['realDonaldTrump']                       \n",
       "93378   []                                        "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsdf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T13:46:46.424254Z",
     "start_time": "2020-09-21T13:46:46.421425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orlando/anaconda3/envs/tfgpu/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF GPU)",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
